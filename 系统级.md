# 系统级
## 方案简介
移动推荐算法
### 整体方案简介
以移动电商平台的真实用户-商品行为数据为基础来构建商品推荐模型
### 分级任务简介
1. 安装hadoop 3.1.2，
2. 完成master-node双节点集群搭建
## 数据集说明
- 数据集大小
1.0GB
- 数据集来源
[阿里天池移动推荐离线赛][1]
## 工具说明
### 工作环境
- Windows 10 ，Vitualbox 6.0
[![vitualbox](https://s2.ax1x.com/2019/05/10/ERQVSO.md.jpg)](https://imgchr.com/i/ERQVSO)
### 虚拟化环境
- Ubuntu 18.04.2 LTS
- master：内存3G 分配储存空间10G host：10.12.223.57
- node：内存1G 分配储存空间10G host：10.12.217.189
[![master](https://s2.ax1x.com/2019/05/10/ERMwRO.jpg)](https://imgchr.com/i/ERMwRO)
[![node](https://s2.ax1x.com/2019/05/10/ERMsLd.jpg)](https://imgchr.com/i/ERMsLd)
### 分布式系统特征及选取原因
1. 分布式文件系统是大数据时代解决大规模数据存储问题的有效解决方案，HDFS 开源实现了GFS，可以利用由廉价硬件构成的计算机集群实现海量数据的分布式存储。
2. HDFS 具有兼容廉价的硬件设备、流数据读写、大数据集、简单的文件模型、强大的跨平台兼容性等特点。但是也要注意到，HDFS 也有自身的局限性，比如不适合低延迟数据访问、无法高效存储大量小文件和不支持多用户写入及任意修改文件等。
3. 块是HDFS的核心概念，一个大的文件会被拆分成很多个块。HDFS采用抽象的块概念，具有支持大规模文件存储、简化系统设计、适合数据备份等优点。
4. HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点和若干个数据节点。名称节点负责管理分布式文件系统的命名空间；数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取。
5. HDFS 采用了冗余数据存储，增强了数据可靠性，加快了数据传输速度。HDFS 还采用了相应的数据存放、数据读取和数据复制策略，来提升系统整体读写响应性能。HDFS 把硬件出错看成一种常态，设计了错误恢复机制。
## 问题挑战
1. 安装过程中踩了不少坑，对Linux系统仍然不是很熟悉
2. 配置集群间网络连接有困难，计算机的网络原理有待进一步学习
3. hadoop的进一步操作有待学习
## 成果展示
### 创建hadoop用户并增加管理员权限
```
$ sudo useradd -m hadoop -s /bin/bash
$ sudo passwd 123456
$ sudo adduser hadoop sudo
```
### 更新apt并安装必要软件
```
$ sudo apt-get update
$ sudo apt-get install vim
```
### 配置ssh无密码登陆
```
$ sudo apt-get install openssh-server
$ cd ~/.ssh/              
$ ssh-keygen -t rsa          
$ cat ./id_rsa.pub >> ./authorized_keys  
$ ssh localhost
```
### 安装Java环境并配置环境变量
```
$ sudo apt-get install openjdk-8-jre openjdk-8-jdk
$ vim ~/.bashrc
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
$ source ~/.bashrc 
```
### 安装hadoop3.1.2
```
$ sudo tar -zxf ~/downloads/hadoop-3.1.2.tar.gz -C /usr/local  
$ cd /usr/local/
$ sudo mv ./hadoop-3.1.2/ ./hadoop    
$ sudo chown -R hadoop ./hadoop   
```
### 运行grep示例
```bash
$ cd /usr/local/hadoop
$ mkdir ./input
$ cp ./etc/hadoop/*.xml ./input  
$ ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output 'dfs[a-z.]+'
$ cat ./output/* 
$ rm -r ./output
```
### 网络配置
```
$ ifconfig
$ sudo vim /etc/hostname 
$ sudo vim /etc/hosts    
$ ping master -c 10   
$ ping node -c 10
```
![network](https://s2.ax1x.com/2019/05/10/ERKq2D.jpg)
### SSH无密码登陆节点
```bash
$ cd ~/.ssh            
$ rm ./id_rsa*           
$ ssh-keygen -t rsa  
$ cat ./id_rsa.pub >> ./authorized_keys
$ scp ~/.ssh/id_rsa.pub hadoop@node:/home/hadoop/
$ mkdir ~/.ssh  #以下三行命令在node中执行                                
$ cat ~/id_rsa.pub >> ~/.ssh/authorized_keys
$ rm ~/id_rsa.pub   
$ ssh node #在master中执行
```
### 配置PATH变量
```
$ vim ~/.bashrc
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
$ source ~/.bashrc
```
### 配置集群环境
1.workers
添加```node```这一行
2.core-site.xml
```xml
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://Master:9000</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>file:/usr/local/hadoop/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
</configuration>
```
3.hdfs-site.xml
```xml
<configuration>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>Master:50090</value>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/usr/local/hadoop/tmp/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/usr/local/hadoop/tmp/dfs/data</value>
        </property>
</configuration>
```
4.mapred-site.xml
```xml
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>Master:10020</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>Master:19888</value>
        </property>
</configuration>
```
5.yarn-site.xml
```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>Master</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
</configuration>
```
6.master上执行
```
$ cd /usr/local
$ sudo rm -r ./hadoop/tmp     
$ sudo rm -r ./hadoop/logs/*   
$ tar -zcf ~/hadoop.master.tar.gz ./hadoop  
$ cd ~
$ scp ./hadoop.master.tar.gz node:/home/hadoop
```
7.node上执行
```
$ sudo rm -r /usr/local/hadoop 
$ sudo tar -zxf ~/hadoop.master.tar.gz -C /usr/local    
$ sudo chown -R hadoop /usr/local/hadoop   
```
### 启动hadoop
```
$ hdfs namenode -format
$ start-dfs.sh
$ start-yarn.sh
$ jps
$ hdfs dfsadmin -report
```
[![master_jps](https://s2.ax1x.com/2019/05/10/ERK0Ds.md.jpg)](https://imgchr.com/i/ERK0Ds)
如图所示，在```master```节点上可以看到NameNode、ResourceManager、SecondrryNameNode进程
[![node_jps](https://s2.ax1x.com/2019/05/10/ERKy5V.md.jpg)](https://imgchr.com/i/ERKy5V)
如图所示，在```node```节点上可以看到DataNode 和 NodeManager 进程
### 执行分布式实例
```
$ hdfs dfs -mkdir -p /user/hadoop
$ hdfs dfs -mkdir input
$ hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml input
```
通过查看 DataNode 的状态，输入文件确实复制到了 DataNode 中，如下图所示：
[![data](https://s2.ax1x.com/2019/05/10/ERK8Et.md.jpg)](https://imgchr.com/i/ERK8Et)
接下来运行```MapReduce```作业
```
$ hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output 'dfs[a-z.]+'
```
[![process](https://s2.ax1x.com/2019/05/10/ER1CPx.md.jpg)](https://imgchr.com/i/ER1CPx)
通过 Web 界面查看任务进度 [http://master:8088/cluster][2]
![overview](https://s2.ax1x.com/2019/05/10/ERKN8S.jpg)
![ERlGU1.jpg](https://s2.ax1x.com/2019/05/10/ERlGU1.jpg)
[![ERlzZ9.md.jpg](https://s2.ax1x.com/2019/05/10/ERlzZ9.md.jpg)](https://imgchr.com/i/ERlzZ9)
[![job](https://s2.ax1x.com/2019/05/10/ER1dJ0.md.jpg)](https://imgchr.com/i/ER1dJ0)
## 心得体会
1. 完成了大数据入门环境hadoop的搭建
2. 完成了在虚拟化环境下安装Linux系统Ubuntu
3. 初步了解了Linux下的基本shell命令
4. 初步了解了vim的基本操作


  [1]: https://tianchi.aliyun.com/competition/entrance/231522/information
  [2]: http://master:8088/cluster